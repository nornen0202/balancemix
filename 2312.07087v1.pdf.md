# Toward Robustness in Multi-label Classifcation:

# A Data Augmentation Strategy against Imbalance and Noise

Hwanjun Song1, Minseok $\text {Kim}^{2}$ , Jae-Gil Lee1

1KAIST, ${}^{2}\mathrm {An}$ mazon

{songhwanjun, jaegil}@kaist.ac.kr, kminseok@amazon.com

## Abstract

Multi-label classifcation poses challenges due to imbalanced and noisy labels in training data. We propose a unifed data augmentation method, named BalanceMix, to address these challenges. Our approach includes two samplers for imbal anced labels, generating minority-augmented instances with high diversity. It also refnes multi-labels at the label-wise granularity, categorizing noisy labels as clean, re-labeled, or ambiguous for robust optimization. Extensive experiments on three benchmark datasets demonstrate that BalanceMix out performs existing state-of-the-art methods. We release the code at https://github.com/DISL-Lab/BalanceMix.

## Introduction

The issue of data-label quality emerges as a major concern in the practical use of deep learning, potentially resulting in catastrophic failures when deploying models in real-world test scenarios (Whang et al. 2021). This concern is magni fed in multi-label classifcation, where instances can be as sociated with multiple labels simultaneously. In this context,AI system robustness is at risk due to diverse types of data label issues, although the task can refect the complex rela tionships present in real-world data (Bello et al. 2021).

The presence of class imbalance occurs when a few majority classes occupy most of the positive labels, and positive-negative imbalance arises due to instances typically having fewer positive labels but numerous negative labels.Such imbalanced labels can dominate the optimization pro cess and lead to underemphasizing the gradients from mi nority classes or positive labels. Additionally, the presence of noisy labels stems from the costly and time-consuming nature of meticulous annotation (Song et al. 2022). Labels can be corrupted by adversaries or system failures (Zhang et al. 2020). Notably, instances have both clean and incorrect labels, therefore resulting in diverse cases of noisy labels.

Three distinct types of noisy labels arise in multi-label classifcation, as illustrated in Fig. 1: mislabeling, where a visible object in the image is labeled incorrectly by a human or machine annotator, such as a dog being labeled as a cat;random fipping, where labels are randomly fipped by an adversary regardless of the presence of other class objects,

Copyright $C$  2024, Association for the Advancement of Artifcial Intelligence (www.aaai.org). All rights reserved.

<!-- DogCatBird DoorBowl Cap Clean Label:1 0 0 1 0 0  Mislabeling:0 1 0 1 0 0  Random Flip:1 1 0 0 0 1  Missing Label:1  -->
![](https://web-api.textin.com/ocr_image/external/5e9f7dc655fa5d74.jpg)


![](https://web-api.textin.com/ocr_image/external/3514df3f63aba460.jpg)

Figure 1: Examples of noisy labels in multi-label classifca tion. 1 and 0 indicate positive and negative labels, symboliz ing the existence of an object class.

such as negative labels for a cat and a bowl being fipped independently to positive labels; and (partially) missing la bels, where even humans cannot fnd all applicable class la bels for each image, and it is more diffcult to detect their absence than to detect their presence (Cole et al. 2021).

Ensuring the robustness of AI systems calls for a holis tic approach that effectively operates within the following settings: clean, noisy, missing, and imbalanced labels at the same time. However, this task is non-trivial given that minor ity and noisy labels have similar behavior in learning, e.g.,larger gradients, making the task even more complicated and challenging. As a result, prior studies have addressed these two problems separately in different setups, assum ing either clean or well-balanced training data‚Äîi.e., imbal anced clean labels (Lin et al. 2017; Ben-Baruch et al. 2021;Du et al. 2023) and well-balanced noisy labels (Zhao and Gomes 2021; Ferreira, Costeira, and Gomes 2021; Shikun et al. 2022; Wei et al. 2023).

We address this challenge using a new data augmentation method, BalanceMix, without complex data preprocessing and architecture change. First, for imbalanced multi-labels,we maintain an additional batch sampler called a minority sampler, which samples the instances containing minority labels with high probability, as illustrated in Fig. 2(a). To counter the limited diversity in oversampling, we interpolate the instances sampled from the minority sampler with those sampled from a random sampler using the Mixup (Zhang et al. 2018) augmentation. By mixing with a higher weight to the random instances, the sparse context of the oversam pled instances literally percolates through the majority of training data without losing diversity. Minority sampling in Fig. 2(a) followed by the Mixup augmentation in Fig. 2(c) is called minority-augmented mixing.

<!-- 3202 c e D  21  ]G L .s c [  1v 78070.2132:v i X r a -->

<!-- Random SamplerClean LabelsRe-labeled LabelsAmbiguous Labels #1#2 Classes #110100#110000 #3#4#210000#211000 #301000#311000 $Œª(&gt;0.$ ùüì) #411000#411000 Minority Sampler + #1#2 ClassesClasses #110110#110100`ùüè $-$ $Œª$ #3#4#200010#200010 #310001#300001 #400000#400010 -->
![](https://web-api.textin.com/ocr_image/external/49e01d108d42785f.jpg)

(b) Fine-grained Label-wise Management.

(a) Minority Sampling (w. Noisy Multi-labels).

Mixup with Refined Multi-labels

<!-- #2 -->
![](https://web-api.textin.com/ocr_image/external/d2881176327558b6.jpg)

<!-- #1 -->
![](https://web-api.textin.com/ocr_image/external/7fd9dfc6fca5a36d.jpg)

<!-- #3 -->
![](https://web-api.textin.com/ocr_image/external/e73963e317b2e6a8.jpg)

<!-- #4 -->
![](https://web-api.textin.com/ocr_image/external/a784adf2ce002e5a.jpg)

(c) Mixing Augmentation.

Figure 2: Overview of BalanceMix. Here with MS-COCO, ‚Äúperson‚Äù and ‚Äúcar‚Äù are the most frequently observed (majority)classes, whereas ‚Äúhair dryer,‚Äù ‚Äúscissor,‚Äù and ‚Äútoaster‚Äù are the least frequently observed (minority) classes in the training data.

Then, for noisy multi-labels, we incorporate fne-grained label-wise management to feed high-quality multi-labels into the augmentation process. Unlike existing robust learn ing methods such as Co-teaching (Han et al. 2018) which consider each instance as a candidate for selection or correc tion, we should move to a fner granularity and consider each label as a candidate. As illustrated in Fig. 2(b), the label wise management step categorizes the entire set of noisy la bels into three subsets: clean labels which are expected to be correct with high probability; re-labeled labels whose fip ping is corrected with high confdence; and ambiguous la bels which need to be downgraded in optimization. Putting our solutions for imbalanced and noisy labels together, Bal anceMix is completed, as illustrated in Fig. 2.

Our technical innovations are successfully incorporated into the well-established techniques of oversampling and Mixup, enabling easy integration into the existing training pipeline. Our contributions are threefold: (1) BalanceMix serves as a versatile data augmentation technique, demon strating reliable performance across clean, noisy, missing,and imbalanced labels. (2) BalanceMix avoids overftting to minority classes and incorrect labels thanks to minority augmented mixing with fne-grained label management. (3)BalanceMix outperforms existing prior arts and reaches $91.7mAP$  on the MS-COCO data, which is the state-of-the art performance with the ResNet backbone.

## Related Work

Multi-label with Imbalance.One of the main trends in this feld is solving long-tail class imbalance and positive negative label imbalance. There have been classical resam pling approaches (Wang, Minku, and Yao 2014; Loyola Gonz¬¥alez et al. 2016) for imbalance, but they are mostly designed for a single-label setup. A common solution for class imbalance with multi-labels is the focal loss (Lin et al. 2017), which down-weights the loss value of each la bel gradually as a model‚Äôs prediction confdence increases,highlighting diffcult-to-learn minority class labels; how ever, it can lead to overftting to incorrect labels. The asym metric focal loss (ASL) (Ben-Baruch et al. 2021) modifes the focal loss to operate differently on positive and negative labels for the imbalance. (Yuan et al. 2023) proposed a bal-ance masking strategy using a graph-based approach.

Multi-label with (Partially) Missing Labels.Annotation in the multi-label setup becomes harder as the number of classes increases. Subsequently, the need to handle missing labels has recently gained a lot of attention. A simple so lution is regarding all the missing labels as negative labels (Wang et al. 2014), but it leads to overftting to incorrect neg ative ones. There have been several studies with deep neu ral networks (DNNs). (Durand, Mehrasa, and Mori 2019)adopted curriculum learning for pseudo-labeling based on model predictions. (Huynh and Elhamifar 2020) used the inferred dependencies among labels and images to prevent overftting. Recently, (Cole et al. 2021) and (Kim et al. 2022,2023) addressed the hardest version, where only a single positive label is provided for each instance. They proposed multiple solutions including label smoothing, expected pos itive regularization, and label selection and correction. How ever, the imbalance problem is overlooked, and all the labels are simply assumed to be clean.

Classifcation with Noisy Labels.For single-label clas sifcation, learning with noisy labels has established multi ple directions. Most approaches are based on the memoriza tion effect of DNNs, in which simple and generalized pat terns are prone to be learned before the overftting to noisy patterns (Arpit et al. 2017). More specifcally, instances with small losses or consistent predictions are treated as clean instances, as in Co-teaching (Han et al. 2018), O2U Net (Huang et al. 2019), and CNLCU (Xia et al. 2022); in stances are re-labeled based on a model‚Äôs predictions for la bel correction, as in SELFIE (Song, Kim, and Lee 2019) and SEAL (Chen et al. 2021). A considerable effort has also been made to use semi-supervised learning, as in DivideMix (Li,Socher, and Hoi 2020) and PES (Bai et al. 2021). In addi tion, a few studies have addressed class imbalance in the noisy single-label setup (Wei et al. 2021; Ding et al. 2022),but they cannot be immediately applied to the multi-label setup owing to their inability to handle the various types of label noise caused by the nature of having both clean and incorrect labels in one instance.

For multi-label classifcation with noisy labels, there has yet to be studied actively owing to the inherent complex-ity including diverse types of label noise and imbalance.CbMLC (Zhao and Gomes 2021) addresses label noise by proposing a context-based classifer, but its architecture is confned to graph neural networks and requires large pre trained word embeddings. A method by Hu et al.(Hu et al.2018) utilizes a teacher-student network with feature trans formation. SELF-ML (Ferreira, Costeira, and Gomes 2021)re-labels an incorrect label using a combination of clean la bels, but it works only when multi-labels can be defned as attributes associated with each other. ASL (Ben-Baruch et al. 2021) solves the problem of mislabeling by shift ing the prediction probability of low-confdence negative la bels, making their losses close to zero in optimization. T estimator (Shikun et al. 2022) solves the estimation problem of the noise transition matrices in the multi-label setting.

Oversampling with Mixup.Prior studies have applied Mixup to address class imbalance (Guo and Wang 2021; Wu et al. 2020; Galdran, Carneiro, and Gonz¬¥alez Ballester 2021;Park et al. 2022). Yet, they mainly focus on single-label classifcation, overlooking positive-negative imbalances and noisy labels. We propose the frst approach that uses predic tive confdence to dynamically adjust the degree of oversam pling for both types of imbalance while employing label wise management for noisy labels.

## Problem Defnition

A multi-label multi-class classifcation problem requires $D$ training data D, a set of two random variables (x, y) which $\mathbf {x}\in \mathcal {X}(\subset$  consists of an instance (d-dimensional feature) $\left.\mathbb {R}^{d}\right)$ and its multi-label $\mathbf {y}\in \{0,1\}^{K},$  where $K$  is the num ber of applicable classes. However, in the presence of la tbaeiln sn oinisceo, rtrheec tn loaibseyl sm ourlitgi-ilnaabteeld from misla $\tilde {\mathbf {y}}\in \{0,1\}^{K}$ b eplionsgs,i brlayn dcoonm mfiapyp innogt, bane de qmuiasls itnog t hlaeb terluse; tlhabate li s, a noisy T lhaubse,l let $\tilde {\mathcal {D}}=$ $\tilde {y_{k}}$ ‚àà $y_{k}\in \mathbf {y}$ yÀú $\left\{\left(\mathbf {x}_{n},\tilde {\mathbf {y}}_{n}\right)\right\}_{n=1}^{N}$  be the noisy training data of size $N$ .

Label Noise Modeling.We defne three types of label noise. From the statistical point of view, (1) mislabeling is defned as class-dependent label noise, where a class ob ject in the image is incorrectly labeled as another class ob ject that may not be visible. The ratio of a class c1 be 0in,g mislabeled as $c_{2}$  is f.o Irnm ucolantterda sbt,y ( 2) random fipping $œÅ_{c_{1}\rightarrow c_{2}}=p\left(\tilde {y}_{c_{1}}=\right.$ $\left.\tilde {y}_{c_{2}}=1\vert y_{c_{1}}=1,y_{c_{2}}=0\right)$ is class-independent label noise, where the presence (or ab $C$ sence) of a class c is randomly fipped with a probability of $œÅ_{c}=p\left(\tilde {y}_{c}=1\vert y_{c}=0\right)=p\left(\tilde {y}_{c}=0\vert y_{c}=1\right)$ h,i sw shciecnha irsi oin cdaen pendent of the presence of other classes. T be caused by an adversary‚Äôs attack or a system failure. Last,(3) missing labels from partial labeling can be considered as a type of label noise, where all missing labels are treated as negative ones.

Optimization.To deal with multi-labels in optimization,the most widely-used approach is solving $K$  binary classif cation problems using the binary cross-entropy (BCE) loss.Given a DNN parameterized by $Œò$ , the DNN is updated via stochastic gradient descent to minimize the expected BCE

<!-- ) P 100  (A n 75 sio i c 50 re P   25 . A 0 vgTen Class Groups  (Sorted by # Positive Labels) -->
![](https://web-api.textin.com/ocr_image/external/e63b370761f58f2f.jpg)

<!-- c e1Pearson correlation d ne0.75coefficient = 0.995 i nf o 0.5 . C d 0.25 e 0 PrTen Class Groups  (Sorted by # Positive Labels) -->
![](https://web-api.textin.com/ocr_image/external/a6df39f99dae9bf5.jpg)

(a) Prediction Confdence. (b) Average Precision (AP).

Figure 3: AP and Prediction confdence in COCO using the BCE loss at the $40\%$  of training epochs, where 80 classes are partitioned into ten groups in the descending order of positive label frequency. The Pearson correlation coeffcient is computed between ten class groups.

loss on the mini-batch $B\subset \tilde {\mathcal {D}},$ 

$$\mathcal {L}(B;Œò)=\frac {1}{\vert B\vert }\sum _{(\mathbf {x},\tilde {\mathbf {y}})\in B}\sum _{k=1}^{K}\text {BCE}\left(f_{\left(\mathbf {x},\tilde {y}_{k}\right)}\right),\quad ,where\tag{1}$$

$$\text {BCE}\left(f_{\left(\mathbf {x},\tilde {y}_{k}\right)}\right)=-\tilde {y}_{k}¬∑\log \left(f_{\left(\mathbf {x},\tilde {y}_{k}\right)}\right)-\left(1-\tilde {y}_{k}\right)¬∑\log \left(1-f_{\left(\mathbf {x},\tilde {y}_{k}\right)}\right)$$

Gfdiveennc et hine pinrsetsaennccee xa,n d $X$  $f_{\left(\mathbf {x},\tilde {y}_{k}\right)}$ n caen,d respectively , afroer tthhee c $k$  $1-f_{\left(\mathbf {x},\tilde {y}_{k}\right)}$  abse o-nth class by the model $Œò$ . BalanceMix is built on top of this standard optimization pipeline for multi-label classifcation.

## Methodology: BalanceMix

Our primary idea is to generate minority-augmented in stances and their reliable multi-labels through data aug mentation. We now detail the two main components, which achieve balanced and robust optimization by minority augmented mixing and label-wise management. The pseu docode of BalanceMix is provided in Appendix A.

### Minority-augmented Mixing

To relieve the class imbalance problem, prior studies either oversample the minority class labels or adjust their loss val ues (Tarekegn, Giacobini, and Michalak 2021). These meth ods are intuitive but rather intensify the overftting problem since they rely on a few minority instances with limited di versity (Guo and Wang 2021). On the other hand, we lever age random instances to increase the diversity of minority instances by separately maintaining two samplers in Fig. 2.

Confdence-based Minority Sampling.Prior oversam pling methods that rely on the frequency of positive labels face two key limitations. First, this frequency alone does not identify the minority multi-labels with low AP values; as il lustrated in Fig. 3(a), the class group with few positive labels does not always have lower AP values due to the complexity of the two types of imbalance in the multi-label setup. Sec ond, there is a risk of overftting because of sticking to the same oversampling policy during the entire training period.

To address these limitations, we frst propose to employ the prediction confdence $f_{\left(\mathbf {x},\tilde {y}_{k}\right)}$ , which exhibits a strong correlation with the AP, as shown in Fig. 3(b). We opt to oversample the instances with low prediction confdence in their multi-labels, as they are expected to contribute the most signifcant increase in the AP. Initially, We defne two conf-dence scores for a specifc class $k$ ,

$\mathrm {P}(k)=\frac {1}{\left|\mathcal {P}_{k}\right|}\sum _{(\mathbf {x},\tilde {\mathbf {y}})\in \mathcal {P}_{k}}f_{\left(\mathbf {x},\tilde {y}_{k}\right)},\quad \mathrm {A}(k)=\frac {1}{\left|\mathcal {A}_{k}\right|}\sum _{(\mathbf {x},\tilde {\mathbf {y}})\in \mathcal {A}_{k}}\left(1-f_{\left(\mathbf {x},\tilde {y}_{k}\right)}\right),$ )

s.t. $\mathcal {P}_{k}=\left\{(\mathbf {x},\tilde {\mathbf {y}})\in \tilde {\mathcal {D}}:\tilde {y}_{k}=1\right\},\mathcal {A}_{k}=\left\{(\mathbf {x},\tilde {\mathbf {y}})\in \tilde {\mathcal {D}}:\tilde {y}_{k}=0\right\}$ 

which are the expected prediction confdences, respectively,for the presence (P) and absence (A) of the $k$ -th class. Next,the confdence score of an instance $(\mathbf {x},\tilde {\mathbf {y}})$ y) is defned by ag gregating Eq. (2) for all the classes,

$$\text {Score}(\mathbf {x},\tilde {\mathbf {y}})=\sum _{k=1}^{K}\mathbf {1}_{\left[\tilde {y}_{k}=1\right]}\mathrm {P}(k)+\mathbf {1}_{\left[\tilde {y}_{k}=0\right]}\mathrm {A}(k).\tag{3}$$

Then, the sampling probability of $(\mathbf {x},\tilde {\mathbf {y}})$ y) is formulated as

$$p_{\text {sampling}}((\mathbf {x},\tilde {\mathbf {y}});\tilde {\mathcal {D}})=\frac {1/\text {Score}(\mathbf {x},\tilde {\mathbf {y}})}{\sum _{\left(\mathbf {x}^{\prime },\tilde {\mathbf {y}}^{\prime }\right)\in \tilde {\mathcal {D}}}1/\text {Score}\left(\mathbf {x}^{\prime },\tilde {\mathbf {y}}^{\prime }\right)}\tag{4}$$

By doing so, we consider positive-negative imbalance to gether with class imbalance by relying on the prediction con fdence, which marks a signifcant difference from existing methods (Galdran, Carneiro, and Gonz¬¥alez Ballester 2021;Park et al. 2022) that considers only the class imbalance of positive labels. Further, our confdence-based sampling dy namically adjusts the degree of oversampling over a training period, mitigating the risk of overftting. Minority instances are initially oversampled with a high probability, but the de gree of oversampling gradually decreases as the imbalance problem gets resolved (see Figure 6 in Appendix B).

Mixing Augmentation.To mix the instances from the two samplers. We adopt the Mixup (Zhang et al. 2018) augmen tation because it can mix two instances even when multi labels are assigned to them. Let $\left(\mathbf {x}_{R},\tilde {\mathbf {y}}_{R}\right)$  and $\left(\mathbf {x}_{M},\tilde {\mathbf {y}}_{M}\right)$ be the instances sampled from the random and minority sam plers, respectively. The minority-augmented instance is gen erated by their interpolation,

$$\mathbf {x}^{mix}=Œª\mathbf {x}_{R}+(1-Œª)\mathbf {x}_{M},\tilde {\mathbf {y}}^{mix}=Œª\tilde {\mathbf {y}}_{R}+(1-Œª)\tilde {\mathbf {y}}_{M}$$

(5)

where $Œª=\max \left(Œª^{\prime },1-Œª^{\prime }\right)$ 

and $Œª^{\prime }\in [0,1]\sim$ Beta(Œ±, Œ±). By the second row of Eq. (5), $Œª$  becomes greater than or equal to 0.5; thus, the instance of the random sampler amplifes diversity, while that of the mi nority sampler adds the context of minority classes. Mixing one random instance and one controlled (minor) instance,instead of mixing two random instances, is a simple yet ef fective strategy, as shown in the evaluation.

### Fine-grained Label-wise Management

Before mixing the two instances by Eq. (5), to make noisy multi-labels reliable in support of robust optimization, we perform label-wise refnement.

Clean Labels.To relieve the imbalance problem in label selection, we separately identify clean labels for each class.Let $L_{\left(\tilde {y}_{k}=1\right)}$ $\text {and}L_{\left(\tilde {y}_{k}=0\right)}$  be the sets of the BCE losses of the positive and negative labels of the $k$ -th class,

$$L_{\left(\tilde {y}_{k}=l\right)}=\left\{\text {BCE}\left(f_{\left(\mathbf {x},\tilde {y}_{k}=l\right)}\right)\vert (\mathbf {x},\tilde {\mathbf {y}})\in \tilde {\mathcal {D}}\right.\quad V\quad \tilde {y}_{k}\in \tilde {\mathbf {y}}\quad V\quad \left.\tilde {y}_{k}=l\right\}$$

(6)where $l$  is 1 or 0 for the positive or negative label.

Clean labels exhibit loss values smaller than noise ones due to the memorization effect of DNNs (Li, Socher, and Hoi 2020). Hence, we ft a bi-modal univariate Gaussian mixture model (GMM) to each set of the BCE losses in using the expectation-maximization (EM) algorithm, returning $2xK$  GMM models for positive and negative labels of $K$  classes,

$$p_{\mathcal {G}}=\left\{\left(\mathcal {G}_{\left(\tilde {y}_{k}=1\right)},\mathcal {G}_{\left(\tilde {y}_{k}=0\right)}\right)\right\}_{k=1}^{K}.\tag{7}$$

Given the BCE loss of x for the $X$  $k$ -th positive or negative label, its clean-label probability is obtained by the posterior probability of the corresponding GMM,

$$p_{\mathcal {G}}\left(\mathbf {x},\tilde {y}_{k}=l\right)=\frac {\mathcal {G}_{\left(\tilde {y}_{k}=l\right)}\left(\operatorname {BCE}\left(f_{\left(\mathbf {x},\tilde {y}_{k}=l\right)}\right)\mid g\right)\cdot \mathcal {G}_{\left(\tilde {y}_{k}=l\right)}(g)}{\mathcal {G}_{\left(\tilde {y}_{k}=l\right)}\left(\operatorname {BCE}\left(f_{\left(\mathbf {x},\tilde {y}_{k}=l\right)}\right)\right)}\tag{8}$$

where $9$  denotes a modality for the small-loss (clean) label.Thus, a label with $p_{\mathcal {G}}>0.5$ is marked as being clean.

The time complexity of GMM modeling is and thus linear to the number of instances $N$ , where $\mathcal {O}(NGD)=$ $\mathcal {O}(N)$ the number of modalities $G=2$  and the number of dimen sions $D=1$ (see (Trivedi et al. 2017) for the proof of the time complexity). Since we model the GMMs once per epoch,the cost involved is expected to be small compared with the training steps of a complex DNN.

Re-labeled Labels.Before the overftting to noisy labels,a model‚Äôs prediction delivers useful underlying information on correct labels (Song, Kim, and Lee 2019). Therefore, we modify the given label if it is not selected as a clean one but the model exhibits high confdence in predictions. To obtain a stable confdence from the model, we ensemble the prediction confdences on two augmented views cre ated by RandAug (Cubuk et al. 2020). Given two differently augmented instances from the original instance $X$  whose $p_{\mathcal {G}}\left(\mathbf {x},\tilde {y}_{k}\right)\leq 0.$ $„ÄÇ$ 5, the $k$ -th label is re-labeled by

$$1/2¬∑\left(f_{\left(\text {aug}_{1}(\mathbf {x}),\tilde {y}_{k}\right)}+f_{\left(\text {aug}_{2}(\mathbf {x}),\tilde {y}_{k}\right)}\right)>ŒµLongrightarrow\tilde {y}_{k}=1,\\ 1/2¬∑\left(f_{\left(\text {aug}_{1}(\mathbf {x}),\tilde {y}_{k}\right)}+f_{\left(\text {aug}_{2}(\mathbf {x}),\tilde {y}_{k}\right)}\right)<1-ŒµLongrightarrow\tilde {y}_{k}=0,\tag{9}$$

$t$ where œµ is the confdence threshold for re-labeling.

Ambiguous Labels.The untouched labels, which are nei ther clean nor re-labeled, are regarded as being ambiguous.These labels are potentially incorrect, but they could hold meaningful information in learning with careful treatment.To squeeze the meaningful information and reduce the po tential risk, for these ambiguous labels, we execute impor tance reweighting which decays a loss based on the clean label probability estimated by Eq. (8).

## Optimization with BalanceMix

Given two instances sampled from the random and minor ity samplers, their multi-labels are frst refned by the label wise management setup. The reliability of each refned la bel is stored as C for clean labels, $R$  for re-labeled labels,and $U$  for ambiguous labels. Then, a minority-augmented instance is generated by Mixup with the mixed multi-labels.The reliability of each label of the augmented instance fol lows that of the instance selected by the random sampler, be cause it always dominates in mixing by $Œª\geq 0.5$ in Eq. (5).

<!-- BCE 13.8 -->
![](https://web-api.textin.com/ocr_image/external/ca0c6ee64a1f1c7b.jpg)

(a) Default.

(c) Methods for Missing Labels.

(b) Methods for Noisy Labels.

<!-- Co-teaching 19.5 -->
![](https://web-api.textin.com/ocr_image/external/73bc075f6f87f038.jpg)

<!-- ASL 69.4 -->
![](https://web-api.textin.com/ocr_image/external/d749a53a5e31c0bf.jpg)

<!-- T-estimator $Imbal,$ $49.9$ -->
![](https://web-api.textin.com/ocr_image/external/ed4cb3afcc186a13.jpg)

<!-- LL-R $Mistabel$ 15.2 -->
![](https://web-api.textin.com/ocr_image/external/f44175d114e8f8cc.jpg)

<!-- LL-Ct $Mislabel$ 43.7 -->
![](https://web-api.textin.com/ocr_image/external/bb29ec0dc514fd73.jpg)

<!-- BalanceMix $Imbal$ 116.5 -->
![](https://web-api.textin.com/ocr_image/external/99eef8c64463f6cc.jpg)

(d) Ours.

Figure 4: Performance ranking (1‚Äì7) from fve different perspectives. BalanceMix is the most versatile to handle diverse types of label issues in multi-label classifcation. A number in a pentagon is its area, roughly meaning the overall performance.


| Class Group  | Class Group  | All  | All  | All  | Many-shot  | Many-shot  | Many-shot  | Medium-shot  | Medium-shot  | Medium-shot  | Few-shot  | Few-shot  | Few-shot  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Category  | Method  | 0% | 20% | 40% | 0% | 20% | 40% | 0% | 20% | 40% | 0% | 20% | 40% |
| Default  | BCE Loss  | 83.4  | 73.1  | 63.8  | 86.9  | 78.4  | 68.4  | 84.5  | 74.0  | 64.3  | 64.3  | 55.5  | 48.0  |
| Noisy Labels  | Co-teaching  | 82.8  | 82.5  | 78.6  | 87.2  | 87.0  | 82.7  | 84.0  | 83.7  | 79.7  | 61.2  | 60.9  | 54.5  |
| Noisy Labels  | ASL  | 85.0  | 82.8  | 80.3  | 88.4  | 87.4  | 85.4  | 86.3  | 84.0  | 81.8  | 67.5  | 62.5  | 55.6  |
| Noisy Labels  | T-estimator  | 84.3  | 82.2  | 80.5  | 87.5  | 86.3  | 85.3  | 85.4  | 83.6  | 81.3  | 67.0  | 59.7  | 61.0  |
| Missing Labels  | LL-R  | 82.5  | 80.7  | 75.3  | 81.0  | 83.9  | 79.8  | 83.8  | 81.8  | 76.7  | 65.7  | 63.1  | 52.6  |
| Missing Labels  | LL-Ct  | 79.4  | 81.3  | 77.4  | 72.3  | 78.8  | 79.3  | 80.5  | 82.6  | 78.8  | 67.0  | 64.3  | 55.9  |
| Proposed  | BalanceMix  | 85.2  | 84.3  | 81.6  | 88.4  | 87.7  | 85.5  | 86.1  | 85.2  | 82.6  | 70.2  | 68.7  | 63.1  |


Table 1: Last mAPs on MS-COCO with mislabeling of $0-40\%$ . The 1st and 2nd best values are in bold and underlined.

The loss function of BalanceMix is defned on the minority augmented mini-batch $B_{mix}$ by

$$\mathcal {L}_{\text {ours}}\left(B_{mix};\Theta \right)=\frac {1}{\left|B_{mix}\right|}\sum _{\left(\mathbf {x}^{mix},\tilde {y}^{mix}\right)\in B_{mix}}\ell \left(\mathbf {x}^{mix},\tilde {\mathbf {y}}^{mix}\right),$$

where $\ell \left(\mathbf {x}^{mix},\mathbf {y}^{mix}\right)=\sum _{k\in \mathrm {CUR}}\text {BCE}\left(f_{\left(\mathbf {x}^{mix},\tilde {y}_{k}^{mix}\right)}\right)$  (10)

$$+\sum _{k\in \mathrm {U}}p_{\mathcal {G}}\left(\mathbf {x}^{mix},\tilde {y}_{k}^{mix}\right)¬∑\text {BCE}\left(f_{\left(\mathbf {x}^{mix},\tilde {y}_{k}^{mix}\right)}\right).$$

We perform standard training for warm-up epochs and then apply the proposed loss function in Eq. (10).

## Evaluation

Datasets.Pascal-VOC (Everingham et al. 2010) and MS COCO (Lin et al. 2014) are the most widely-used datasets with well-curated labels of 20 and 80 common classes. In contrast, DeepFashion (Liu et al. 2016) is a real-world in shopping dataset with noisy weakly-annotated labels for 1, 000 descriptive attributes.

Imbalanced and Noisy Labels.The three datasets con tain different levels of natural imbalance. Pascal-VOC, MS COCO, and DeepFashion have the class imbalance ratios1of 14, 339, and 239, and the positive-negative imbalance ra tios of 13, 27, and 3, respectively. See the detailed analysis of the imbalance in Appendix C. We artifcially contami nate Pascal-VOC and MS-COCO to add three types of label noise. First, for mislabeling, we inject class-dependent label noise. Given a noise rate $T$ , the presence of the $i$ -th class is mislabeled as that of the $j$ -th class with a probability of

1The ratio of the number of the instances in the most frequent class to that of the instances in the least frequent class.

$œÅ_{i\rightarrow j}$ ; we follow the protocol used for a long-tail noisy label setup (Wei et al. 2021). For the two different classes $i$  and $j$ ,

$$œÅ_{i\rightarrow j}=p\left(\tilde {y}_{i}=0,\tilde {y}_{j}=1\vert y_{i}=1\right)=œÑ¬∑N_{j}/\left(N-N_{i}\right),\tag{11}$$

where $N_{i}$  is the number of positive labels for the $i$ -th class.Second, for random fipping, all positive and negative la bels are fipped independently with the probability of œÑ. $7$ Third, for missing labels, we follow the single positive label setup (Kim et al. 2022), where one positive label is selected at random and the other positive labels are dropped.

Algorithms.We use the ResNet-50 backbone pre-trained on ImageNet-1K and fne-tune using SGD with a mo mentum of 0.9 and resolution of $448x$ 448. We com pare BalanceMix with a standard method using the BCE loss (Default) and fve state-of-the-art methods, categorized into two groups. The former is to handle noisy labels based on instance-level selection, loss reweighting, and noise tran sition matrix estimation‚ÄîCo-teaching (Han et al. 2018),ASL (Ben-Baruch et al. 2021), and T-estimator (Shikun et al.2022). The latter is to handle missing labels based on la bel rejection and correction‚ÄîLL-R and LL-Ct (Kim et al.2022). For data augmentation, we apply RandAug and Mixup to all methods, except Default using only RandAug.The results of Default with Mixup are presented in Table 5.

As for our hyperparameters, the coeffcient $a$  for Mixup is set to be 4.0; and the confdence threshold $E$  for re-labeling is set to be 0.975 for the standard, mislabeling, and random fipping settings with multiple positive labels, but it is set to be 0.550 for the missing label setting with a single posi tive label. More details of confguration and hyperparameter search can be found in Appendices D and E.

Evaluation Metric.We report the overall validation (or test) mAP at the last epoch over three disjoint class sub-


| Class Group  | Class Group  | All  | All  | All  | Many-shot  | Many-shot  | Many-shot  | Medium-shot  | Medium-shot  | Medium-shot  | Few-shot  | Few-shot  | Few-shot  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Category  | Method  | 0% | 20% | 40% | 0% | 20% | 40% | 0% | 20% | 40% | 0% | 20% | 40% |
| Default  | BCE Loss  | 83.4  | 59.8  | 43.5  | 86.9  | 71.2  | 65.1  | 84.5  | 60.6  | 43.2  | 64.3  | 38.9  | 30.6  |
| Noisy Labels  | Co-teaching  | 82.8  | 65.5  | 43.6  | 87.2  | 76.1  | 61.9  | 84.0  | 66.8  | 43.8  | 61.2  | 38.3  | 25.9  |
| Noisy Labels  | ASL  | 85.0  | 75.0  | 66.2  | 88.4  | 84.4  | 82.8  | 86.3  | 77.0  | 67.7  | 67.5  | 39.2  | 30.8  |
| Noisy Labels  | T-estimator  | 84.3  | 74.3  | 69.9  | 87.5  | 82.6  | 80.8  | 85.4  | 76.0  | 71.5  | 67.4  | 43.6  | 39.1  |
| Missing Labels  | LL-R  | 82.5  | 74.0  | 69.3  | 81.0  | 77.2  | 76.6  | 83.8  | 75.8  | 71.0  | 65.7  | 46.0  | 38.6  |
| Missing Labels  | LL-Ct  | 79.4  | 73.2  | 70.1  | 72.3  | 75.5  | 76.5  | 80.5  | 75.0  | 71.8  | 67.0  | 45.5  | 41.1  |
| Proposed  | BalanceMix  | 85.2  | 76.5  | 74.5  | 88.4  | 84.5  | 81.3  | 86.1  | 78.2  | 76.3  | 70.2  | 46.1  | 43.0  |


Table 2: Last mAPs on MS-COCO with random fipping of 0‚Äì40%. The 1st and 2nd best values are in bold and underlined.


| Datasets  | Datasets  | MS-COCO  | MS-COCO  | MS-COCO  | MS-COCO  | Pascal-VOC  | Pascal-VOC  | Pascal-VOC  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Category  | Method  | All  | Many  | Medium  | Few  | All  | Medium  | Few  |
| Default  | BCE Loss  | 69.7  | 71.7  | 70.6  | 54.4  | 85.7  | 89.2  | 84.2  |
| Noisy Labels  | Co-teaching  | 68.1  | 61.5  | 69.2  | 59.1  | 80.9  | 87.2  | 78.1  |
| Noisy Labels  | ASL  | 73.3  | 77.7  | 74.7  | 49.2  | 86.8  | 82.1  | 88.8  |
| Noisy Labels  | T-estimator  | 16.8  | 43.2  | 16.3  | 3.3  | 86.2  | 88.9  | 85.0  |
| Missing Labels  | LL-R  | 74.2  | 75.4  | 75.3  | 58.7  | 89.1  | 91.5  | 88.1  |
| Missing Labels  | LL-Ct  | 76.9  | 77.4  | 78.2  | 57.6  | 89.3  | 91.5  | 88.3  |
| Proposed  | BalanceMix  | 77.4  | 76.2  | 78.5  | 61.3  | 92.6  | 94.5  | 91.8  |


Table 3: Last mAPs on MS-COCO and Pascal-VOC in the missing label (single positive label) setup.

sets: many-shot (more than 10,000 positive labels), medium shot (from 1,000 to 10,000 positive labels), and few-shot (less than 1,000 positive labels) classes. The result at the last epoch is commonly used in the literature on robustness to label noise (Han et al. 2018). We repeat every task thrice,and see Appendix F for the standard error.

## Overall Analysis on Five Perspectives

Fig. 4 shows the overall performance rankings aggregated2on Pascal-VOC and MS-COCO for fve different perspec tives: ‚ÄúClean‚Äù for when label noise is not injected, ‚ÄúMisla bel‚Äù for when labels are mislabeled with the noise ratio of 20‚Äì40%, ‚ÄúRand. Flip‚Äù for when labels are randomly fipped with the noise ratio of 20‚Äì40%, ‚ÄúMissing‚Äù for when the sin gle positive label setup is used, and ‚ÄúImbal.‚Äù for when few shot classes without label noise are used.

Only BalanceMix operates in all scenarios with high per formance: its minority-augmented mixing overcomes the problem of imbalanced labels while its fne-grained label wise management adds robustness to diverse types of label noise. Except BalanceMix, the fve existing methods have pros and cons. The three methods of handling noisy labels in Fig. 4(b) generally perform better for mislabeling and ran dom fipping than the others; but the instance-level selec tion of Co-teaching is not robust to random fipping where a signifcant number of negative labels are fipped to positive ones. In contrast, the two methods of handling missing la bels in Fig. 4(c) perform better with the existence of missing labels than Co-teaching, ASL, and T-estimator. LL-Ct (label correction) is more suitable than LL-R (label rejection) for mislabeling and random fipping since label correction has a

2For each perspective, we respectively compute the ranking on each dataset and then sum up the rankings to get the fnal one.


| Class Group  | All  | Many  | Medium  | Few  |
| --- | --- | --- | --- | --- |
| BCE Loss  | 75.2  | 93.4  | 84.4  | 53.4  |
| Co-teaching  | 66.8  | 90.7  | 81.3  | 32.8  |
| ASL  | 76.4  | 94.4  | 85.2  | 55.4  |
| T-estimator  | 75.4  | 94.7  | 84.8  | 53.1  |
| LL-R  | 75.3  | 93.3  | 84.2  | 53.8  |
| LL-Ct  | 75.2  | 92.6  | 84.2  | 53.8  |
| BalanceMix  | 77.0  | 95.2  | 85.6  | 56.4  |


Table 4: mAPs on DeepFashion with real-world noisy multi-labels using seven multi-label classifcation methods.

potential to re-label some of incorrect labels. For the imbal ance, ASL shows reasonable performance on the few-shot subset by adopting a modifed focal loss.

# Results on Imbalanced and Noisy Labels

We evaluate the performance of BalanceMix on MS-COCO with three types of synthetic label noise and on DeepFashion with real-world label noise. We defer the results on Pascal VOC to Appendix F for the sake of space.

Mislabeling (Table 1).BalanceMix achieves not only the best overall mAP (see the ‚ÄúAll‚Äù column) with varying misla beling ratios, but also the best mAP on few-shot classes (see the ‚ÄúFew-shot‚Äù column). It shows higher robustness even compared with the three methods designed for noisy labels.ASL performs well among the compared methods, but its weighting scheme of pushing higher weights to diffcult to-learn labels could lead to overftting to diffcult incor rect labels; hence, when the noise ratio increases, its per formance rapidly degrades from 67.5% to 55.6% in the few shot classes. Both methods for missing labels perform bet ter than the default method (BCE), but are still vulnerable to mislabeling.


| Component  | Clean Label  | Mislabel 40% | Rand Flip $40\%$ | Missing Label  | Overall (Mean)  |
| --- | --- | --- | --- | --- | --- |
| Default (BCE Loss)  | 83.4  | 63.3  | 43.0  | 72.6  | 65.6  |
| + Random Sampler (‚âàMixup) | 84.2 (+0.8) | 67.4 (+3.3) | 64.9 (+21.9) | 73.3 $(+0.7)$ | 72.5 (+6.9) |
| + Minority Sampler (in Eq. (4))  | $85.1(+1.7)$ | 70.2 (+6.9) | $67.2(+24.2)$ | $74.2(+1.6)$ | $74.2(+8.6)$ |
| + Clean Labels (in Eq. (8))  | $84.9(-0.2)$ | 76.1 (+5.9) | 74.9 (+7.7) | $74.6(+0.4)$ $(+1.5)$ | $77.6(+3.4)$ |
| + Re-labeled Labels (in Eq. (9))  | $85.3(+0.4)$ | 80.2 (+3.9) | 74.9 (+0.0) | 76.  | 79.1 (+1.5) |
| + Ambiguous Labels (in Eq. (10))  | $85.3(+0.0)$ | 81.6 (+1.4) | 74.5 (‚àí0.4) | $77.4(+1.3)$ | $79.7(+0.6)$ |


Table 5: Component analysis of BalanceMix on MS-COCO. The values in parentheses are the gain caused by each component.

Random Flipping (Table 2).This is more challenging than mislabeling noise, in considering that even negative la bels are fipped by a given noise ratio. Accordingly, the mAP of Co-teaching and ASL drops signifcantly when the noise ratio reaches $40\%$  (see the ‚ÄúAll‚Äù column), which implies that instance selection in Co-teaching and loss reweight ing in ASL are ineffective to overcome random fipping.T-estimator shows a better result at the noise ratio of $40\%$ than ASL by estimating the noise transition matrix per class.Overall, BalanceMix achieves higher robustness against a high fipping ratio of $40\%$  with fne-grained label-wise man agement; its performance drops by only $10.7\%p$ , which is much smaller than 39. $2\%p,$  $18.8\%p$ , and $14.4\%p$  of Co teaching, ASL, and T-estimator, respectively. Thus, it main tains the best mAP for all class subsets in general.

Missing Labels (Table 3).Unlike the mislabeling and ran dom fipping, LL-R and LL-Ct generally show higher mAPs than the methods for noisy labels, because LL-R and LL-Ct are designed to reject or re-label unobserved positive labels that are erroneously considered as negative ones. Likewise,the label-wise management of BalanceMix includes the re labeling process, fxing incorrect positive and negative labels to be correct. In addition, it shows higher mAP in the few shot classes than LL-Ct due to the consideration of imbal anced labels. Thus, it consistently maintains its performance dominance. Meanwhile, T-estimator performs badly in MS COCO due to the complexity of transition matrix estimation.

Real-world Noisy Labels (Table 4).A real-world noisy dataset, DeepFashion, likely contains all the label noises‚Äîmislabeling, random fipping, and missing labels‚Äîalong with class imbalance. Therefore, our motivation for a holis tic approach is of importance for real use cases.

The relatively small performance gain is attributed to a small percentage (around $8\%$ ) of noise labels (Song et al.2022) in DeepFashion, because its fne-grained labels were annotated via a crowd-sourcing platform which can be rel atively reliable. The performance gain will increase for datasets with a higher noise ratio.

# Component Ablation Study

We conduct a component ablation study by adding the main components one by one on top of the default method. Table 5 summarizes the mAP and average performance of each of fve variants. The frst variant of using only a random sam pler is equivalent to the original Mixup.

First, using only a random sampler like Mixup does not suffciently improve the model performance, but adding the minority sampler achieves suffcient improvement because it takes imbalanced labels into account. Second, exploiting


| Method  | Backbone  | Resolution  | $mAP$(All)  |
| --- | --- | --- | --- |
| MS-CMA  | ResNet-101  | $448x448$ | 83.8  |
| ASL  | ResNet-101  | $448x448$ | 85.0  |
| ML-Decoder  | ResNet-101  | $448x448$ | 87.1  |
| BalanceMix  | ResNet-101  | $448x448$ | 87.4 (+0.3) |
| ASL  | TResNet-L  | $448x448$ | 88.4  |
| Q2L  | TResNet-L  | $448x448$ | 89.2  |
| ML-Decoder  | TResNet-L  | $448x448$ | 90.0  |
| BalanceMix  | TResNet-L  | $448x448$ | 90.5 (+0.5) |
| ML-Decoder  | TResNet-L  | $640x640$ | 91.1  |
| ML-Decoder  | TResNet-XL  | $640x640$ | 91.4  |
| BalanceMix  | TResNet-L  | $640x640$ | 91.7 (+0.6) |


Table 6: State-of-the-art comparison on MS-COCO. The values in parentheses are the improvements over the latest method using the same backbone.

only the selected clean labels increases the mAP when pos itive labels are corrupted with mislabeling and random fip ping. However, this approach is not that benefcial in the clean and missing label setups, where all positive labels are regarded as being clean; it also simply discards all (expect edly) unclean negative labels without any treatment. Third,re-labeling complements the limitation of clean label se lection, providing additional mAP gains in most scenarios.Fourth, using ambiguous labels adds further mAP improve ment except for the random fipping setup.

In summary, since all the components in BalanceMix gen erally add a synergistic effect, leveraging all of them is rec ommended for use in practice. In Appendix G, we (1) ana lyze the impact of minority-augmented mixing on diversity changes, (2) provide the pure effect of label-wise manage ment, and (3) report its accuracy in selecting clean labels and re-labeling incorrect labels.

# State-of-the-art Comparison on MS-COCO

We compare BalanceMix with several methods showing the state-of-the-art performance with a ResNet backbone on MS-COCO. The results are borrowed from Ridnik et al. (Ridnik et al. 2023), and we follow exactly the same set ting in backbones, image resolution, and data augmentation.BalanceMix is implemented on top of ML-Decoder for com parison. All backbones are pre-trained on ImageNet. The compared methods are developed without consideration of label noise, but we fnd out that MS-COCO originally has noisy labels (see Appendix H for examples).

Table 6 summarizes the best mAP on MS-COCO with out synthetic noise injection. For the $448x448$  resolution,BalanceMix improves the mAP by 0.3‚Äì0.5%p when using $0.3-0.5\%p$  ResNet-101 and TResNet-L. For the $640x640$  resolution, its

improvement over ML-Decoder becomes 0.6%p when using TResNet-L. The 91.7mAP of BalanceMix with TResNet L is even higher than the 91.4mAP of ML-Decoder with TResNet-XL.

# Conclusion

We propose BalanceMix, which can handle imbalanced labels and diverse types of label noise. The minority augmented mixing allows for adding sparse context in mi nority classes to majority classes without losing diversity.The label-wise management realizes a robust way of ex ploiting noisy multi-labels without overftting. Through ex periments using real-world and synthetic noisy datasets, we verify that BalanceMix outperforms state-of-the-art methods in each setting of mislabeling, fipping, and missing labels,with the co-existence of severe class imbalance. Overall, this work will inspire subsequent studies to handle imbalanced and noisy labels in a holistic manner.

# Acknowledgements

This work was supported by Institute of Information &Communications Technology Planning & Evaluation (IITP)grant funded by the Korea government (MSIT) (No. 20200-00862, DB4DL: High-Usability and Performance In Memory Distributed DBMS for Deep Learning). Addition ally, this work was partly supported by the FOUR Brain Ko rea 21 Program through the National Research Foundation of Korea (NRF-5199990113928).

# References

Arpit, D.; Jastrzebski, S.; Ballas, N.; Krueger, D.; Bengio,E.; Kanwal, M. S.; Maharaj, T.; Fischer, A.; Courville, A.;Bengio, Y.; et al. 2017. A closer look at memorization in deep networks. In ICML, 233‚Äì242.

Bai, Y.; Yang, E.; Han, B.; Yang, Y.; Li, J.; Mao, Y.; Niu,G.; and Liu, T. 2021. Understanding and improving early stopping for learning with noisy labels. In NeurIPS, 24392‚Äì24403.

Bello, M.; N¬¥apoles, G.; Vanhoof, K.; and Bello, R. 2021.Data quality measures based on granular computing for multi-label classifcation. Information Sciences, 560: 51‚Äì67.

Ben-Baruch, E.; Ridnik, T.; Zamir, N.; Noy, A.; Friedman,I.; Protter, M.; and Zelnik-Manor, L. 2021. Asymmetric loss for multi-label classifcation. In ICCV, 82‚Äì91.

Chen, P.; Ye, J.; Chen, G.; Zhao, J.; and Heng, P.-A. 2021.Beyond class-conditional assumption: A primary attempt to combat instance-dependent label noise. In AAAI, 11442‚Äì11450.

Cole, E.; Mac Aodha, O.; Lorieul, T.; Perona, P.; Morris, D.;and Jojic, N. 2021. Multi-label learning from single positive labels. In CVPR, 933‚Äì942.

Cubuk, E. D.; Zoph, B.; Shlens, J.; and Le, Q. V. 2020. Ran daugment: Practical automated data augmentation with a re duced search space. In CVPRW, 702‚Äì703.

Ding, Y.; Zhou, T.; Zhang, C.; Luo, Y.; Tang, J.; and Gong,C. 2022. Multi-class Label Noise Learning via Loss Decom position and Centroid Estimation. In SDM, 253‚Äì261.Du, Y.; Shen, J.; Zhen, X.; and Snoek, C. G. 2023.Su perDisco: Super-Class Discovery Improves Visual Recog nition for the Long-Tail. In CVPR, 19944‚Äì19954.

Durand, T.; Mehrasa, N.; and Mori, G. 2019. Learning a deep convnet for multi-label classifcation with partial la bels. In CVPR, 647‚Äì657.

Everingham, M.; Van Gool, L.; Williams, C. K.; Winn, J.;and Zisserman, A. 2010. The PASCAL visual object classes (VOC) challenge. International Journal of Computer Vision,88(2): 303‚Äì338.

Ferreira, B. Q.; Costeira, J. P.; and Gomes, J. P. 2021. Ex plainable Noisy Label Flipping for Multi-Label Fashion Im age Classifcation. In CVPRW, 3916‚Äì3920.

Galdran, A.; Carneiro, G.; and Gonz¬¥alez Ballester, M. A.2021. Balanced-mixup for highly imbalanced medical im age classifcation. In MICCAI, 323‚Äì333.

Guo, H.; and Wang, S. 2021. Long-tailed multi-label vi sual recognition by collaborative training on uniform and re-balanced samplings. In CVPR, 15089‚Äì15098.

Han, B.; Yao, Q.; Yu, X.; Niu, G.; Xu, M.; Hu, W.; Tsang,I.; and Sugiyama, M. 2018. Co-teaching: Robust training of deep neural networks with extremely noisy labels.In NeurIPS, 8536‚Äì8546.

Hu, M.; Han, H.; Shan, S.; and Chen, X. 2018. Multi-label learning from noisy labels with non-linear feature transfor mation. In ACCV, 404‚Äì419.

Huang, J.; Qu, L.; Jia, R.; and Zhao, B. 2019. O2u-net: A simple noisy label detection approach for deep neural net works. In ICCV, 3326‚Äì3334.

Huynh, D.; and Elhamifar, E. 2020. Interactive multi-label cnn learning with partial labels. In CVPR, 9423‚Äì9432.

Kim, Y.; Kim, J. M.; Akata, Z.; and Lee, J. 2022. Large Loss Matters in Weakly Supervised Multi-Label Classifcation. In CVPR, 14156‚Äì14165.

Kim, Y.; Kim, J. M.; Jeong, J.; Schmid, C.; Akata, Z.; and Lee, J. 2023. Bridging the Gap between Model Explanations in Partially Annotated Multi-label Classifcation. In CVPR,3408‚Äì3417.

Lanchantin, J.; Wang, T.; Ordonez, V.; and Qi, Y. 2021. Gen eral multi-label image classifcation with transformers. In CVPR, 16478‚Äì16488.

Li, J.; Socher, R.; and Hoi, S. C. 2020. DivideMix: Learning with noisy labels as semi-supervised learning. In ICLR.

Lin, T.-Y.; Goyal, P.; Girshick, R.; He, K.; and Doll¬¥ar, P.2017. Focal loss for dense object detection. In CVPR, 2980‚Äì2988.

Lin, T.-Y.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ra manan, D.; Doll¬¥ar, P.; and Zitnick, C. L. 2014. Microsoft COCO: Common objects in context. In ECCV, 740‚Äì755.

Liu, S.; Zhang, L.; Yang, X.; Su, H.; and Zhu, J. 2021.Query2label: A simple transformer way to multi-label clas sifcation. arXiv preprint arXiv:2107.10834.

Liu, Z.; Luo, P.; Qiu, S.; Wang, X.; and Tang, X. 2016.DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations. In CVPR, 1096‚Äì1104.

Loyola-Gonz¬¥alez, O.; Mart¬¥ƒ±nez-Trinidad, J. F.; Carrasco Ochoa, J. A.; and Garc¬¥ƒ±a-Borroto, M. 2016. Study of the im pact of resampling methods for contrast pattern based clas sifers in imbalanced databases. Neurocomputing, 175: 935‚Äì947.

Park, S.; Hong, Y.; Heo, B.; Yun, S.; and Choi, J. Y. 2022.The Majority Can Help The Minority: Context-rich Minor ity Oversampling for Long-tailed Classifcation. In CVPR,6887‚Äì6896.

Ridnik, T.; Sharir, G.; Ben-Cohen, A.; Ben-Baruch, E.; and Noy, A. 2023. ML-Decoder: Scalable and versatile classif cation head. In WACV, 32‚Äì41.

Shikun, L.; Xiaobo, X.; Hansong, Z.; Yibing, Z.; Shim ing, G.; and Tongliang, L. 2022. Estimating Noise Tran sition Matrix with Label Correlations for Noisy Multi-Label Learning. In NeurIPS.

Song, H.; Kim, M.; and Lee, J.-G. 2019. SELFIE: Refur bishing unclean samples for robust deep learning. In ICML,5907‚Äì5915.

Song, H.; Kim, M.; Park, D.; Shin, Y.; and Lee, J.-G. 2022.Learning from noisy labels with deep neural networks: A survey. IEEE TNNLS.

Tarekegn, A. N.; Giacobini, M.; and Michalak, K. 2021. A review of methods for imbalanced multi-label classifcation.Pattern Recognition, 118: 107965.

Trivedi, S. K.; Dey, S.; Kumar, A.; and Panda, T. K. 2017.Handbook of research on advanced data mining techniques and applications for business intelligence. IGI Global.

Wang, Q.; Shen, B.; Wang, S.; Li, L.; and Si, L. 2014. Binary codes embedding for fast image tagging with incomplete la bels. In ECCV, 425‚Äì439.

Wang, S.; Minku, L. L.; and Yao, X. 2014. Resampling based ensemble methods for online class imbalance learn ing. IEEE Transactions on Knowledge and Data Engineer ing, 27(5): 1356‚Äì1368.

Wei, Q.; Feng, L.; Sun, H.; Wang, R.; Guo, C.; and Yin,Y. 2023. Fine-grained classifcation with noisy labels. In CVPR, 11651‚Äì11660.

Wei, T.; Shi, J.-X.; Tu, W.-W.; and Li, Y.-F. 2021.Ro bust long-tailed learning under label noise. arXiv preprint arXiv:2108.11569.

Whang, S. E.; Roh, Y.; Song, H.; and Lee, J.-G. 2021.Data Collection and Quality Challenges in Deep Learn ing: A Data-Centric AI Perspective.arXiv preprint arXiv:2112.06409.

Wu, T.; Huang, Q.; Liu, Z.; Wang, Y.; and Lin, D. 2020.Distribution-balanced loss for multi-label classifcation in long-tailed datasets. In ECCV, 162‚Äì178.

Xia, X.; Liu, T.; Han, B.; Gong, M.; Yu, J.; Niu, G.; and Sugiyama, M. 2022. Sample selection with uncertainty of losses for learning with noisy labels. In ICLR.

Yuan, J.; Zhang, Y.; Shi, Z.; Geng, X.; Fan, J.; and Rui, Y.2023. Balanced masking strategy for multi-label image clas sifcation. Neurocomputing, 522: 64‚Äì72.

Zhang, H.; Cisse, M.; Dauphin, Y. N.; and Lopez-Paz, D.2018. Mixup: Beyond empirical risk minimization. In ICLR.Zhang, M.; Hu, L.; Shi, C.; and Wang, X. 2020. Adversarial label-fipping attack and defense for graph neural networks.In ICDM, 791‚Äì800.

Zhang, S.; Li, Z.; Yan, S.; He, X.; and Sun, J. 2021. Distri bution alignment: A unifed framework for long-tail visual recognition. In CVPR, 2361‚Äì2370.

Zhao, W.; and Gomes, C. 2021. Evaluating multi-label clas sifers with noisy labels. arXiv preprint arXiv:2102.08427.

# References

Arpit, D.; Jastrzebski, S.; Ballas, N.; Krueger, D.; Bengio,E.; Kanwal, M. S.; Maharaj, T.; Fischer, A.; Courville, A.;Bengio, Y.; et al. 2017. A closer look at memorization in deep networks. In ICML, 233‚Äì242.

Bai, Y.; Yang, E.; Han, B.; Yang, Y.; Li, J.; Mao, Y.; Niu,G.; and Liu, T. 2021. Understanding and improving early stopping for learning with noisy labels. In NeurIPS, 24392‚Äì24403.

Bello, M.; N¬¥apoles, G.; Vanhoof, K.; and Bello, R. 2021.Data quality measures based on granular computing for multi-label classifcation. Information Sciences, 560: 51‚Äì67.

Ben-Baruch, E.; Ridnik, T.; Zamir, N.; Noy, A.; Friedman,I.; Protter, M.; and Zelnik-Manor, L. 2021. Asymmetric loss for multi-label classifcation. In ICCV, 82‚Äì91.

Chen, P.; Ye, J.; Chen, G.; Zhao, J.; and Heng, P.-A. 2021.Beyond class-conditional assumption: A primary attempt to combat instance-dependent label noise. In AAAI, 11442‚Äì11450.

Cole, E.; Mac Aodha, O.; Lorieul, T.; Perona, P.; Morris, D.;and Jojic, N. 2021. Multi-label learning from single positive labels. In CVPR, 933‚Äì942.

Cubuk, E. D.; Zoph, B.; Shlens, J.; and Le, Q. V. 2020. Ran daugment: Practical automated data augmentation with a re duced search space. In CVPRW, 702‚Äì703.

Ding, Y.; Zhou, T.; Zhang, C.; Luo, Y.; Tang, J.; and Gong,C. 2022. Multi-class Label Noise Learning via Loss Decom position and Centroid Estimation. In SDM, 253‚Äì261.

Du, Y.; Shen, J.; Zhen, X.; and Snoek, C. G. 2023.Su perDisco: Super-Class Discovery Improves Visual Recog nition for the Long-Tail. In CVPR, 19944‚Äì19954.

Durand, T.; Mehrasa, N.; and Mori, G. 2019. Learning a deep convnet for multi-label classifcation with partial la bels. In CVPR, 647‚Äì657.

Everingham, M.; Van Gool, L.; Williams, C. K.; Winn, J.;and Zisserman, A. 2010. The PASCAL visual object classes (VOC) challenge. International Journal of Computer Vision,88(2): 303‚Äì338.

Ferreira, B. Q.; Costeira, J. P.; and Gomes, J. P. 2021. Ex plainable Noisy Label Flipping for Multi-Label Fashion Im age Classifcation. In CVPRW, 3916‚Äì3920.

Galdran, A.; Carneiro, G.; and Gonz¬¥alez Ballester, M. A.2021. Balanced-mixup for highly imbalanced medical im age classifcation. In MICCAI, 323‚Äì333.

Guo, H.; and Wang, S. 2021. Long-tailed multi-label vi sual recognition by collaborative training on uniform and re-balanced samplings. In CVPR, 15089‚Äì15098.

Han, B.; Yao, Q.; Yu, X.; Niu, G.; Xu, M.; Hu, W.; Tsang,I.; and Sugiyama, M. 2018. Co-teaching: Robust training of deep neural networks with extremely noisy labels.In NeurIPS, 8536‚Äì8546.

Hu, M.; Han, H.; Shan, S.; and Chen, X. 2018. Multi-label learning from noisy labels with non-linear feature transfor mation. In ACCV, 404‚Äì419.

Huang, J.; Qu, L.; Jia, R.; and Zhao, B. 2019. O2u-net: A simple noisy label detection approach for deep neural net works. In ICCV, 3326‚Äì3334.

Huynh, D.; and Elhamifar, E. 2020. Interactive multi-label cnn learning with partial labels. In CVPR, 9423‚Äì9432.

Kim, Y.; Kim, J. M.; Akata, Z.; and Lee, J. 2022. Large Loss Matters in Weakly Supervised Multi-Label Classifcation. In CVPR, 14156‚Äì14165.

Kim, Y.; Kim, J. M.; Jeong, J.; Schmid, C.; Akata, Z.; and Lee, J. 2023. Bridging the Gap between Model Explanations in Partially Annotated Multi-label Classifcation. In CVPR,3408‚Äì3417.

Lanchantin, J.; Wang, T.; Ordonez, V.; and Qi, Y. 2021. Gen eral multi-label image classifcation with transformers. In CVPR, 16478‚Äì16488.

Li, J.; Socher, R.; and Hoi, S. C. 2020. DivideMix: Learning with noisy labels as semi-supervised learning. In ICLR.

Lin, T.-Y.; Goyal, P.; Girshick, R.; He, K.; and Doll¬¥ar, P.2017. Focal loss for dense object detection. In CVPR, 2980‚Äì2988.

Lin, T.-Y.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ra manan, D.; Doll¬¥ar, P.; and Zitnick, C. L. 2014. Microsoft COCO: Common objects in context. In ECCV, 740‚Äì755.

Liu, S.; Zhang, L.; Yang, X.; Su, H.; and Zhu, J. 2021.Query2label: A simple transformer way to multi-label clas sifcation. arXiv preprint arXiv:2107.10834.

Liu, Z.; Luo, P.; Qiu, S.; Wang, X.; and Tang, X. 2016.DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations. In CVPR, 1096‚Äì1104.

Loyola-Gonz¬¥alez, O.; Mart¬¥ƒ±nez-Trinidad, J. F.; Carrasco Ochoa, J. A.; and Garc¬¥ƒ±a-Borroto, M. 2016. Study of the im pact of resampling methods for contrast pattern based clas sifers in imbalanced databases. Neurocomputing, 175: 935‚Äì947.

Park, S.; Hong, Y.; Heo, B.; Yun, S.; and Choi, J. Y. 2022.The Majority Can Help The Minority: Context-rich Minor ity Oversampling for Long-tailed Classifcation. In CVPR,6887‚Äì6896.

Ridnik, T.; Sharir, G.; Ben-Cohen, A.; Ben-Baruch, E.; and Noy, A. 2023. ML-Decoder: Scalable and versatile classif cation head. In WACV, 32‚Äì41.

Shikun, L.; Xiaobo, X.; Hansong, Z.; Yibing, Z.; Shim ing, G.; and Tongliang, L. 2022. Estimating Noise Tran sition Matrix with Label Correlations for Noisy Multi-Label Learning. In NeurIPS.

Song, H.; Kim, M.; and Lee, J.-G. 2019. SELFIE: Refur bishing unclean samples for robust deep learning. In ICML,5907‚Äì5915.

Song, H.; Kim, M.; Park, D.; Shin, Y.; and Lee, J.-G. 2022.Learning from noisy labels with deep neural networks: A survey. IEEE TNNLS.

Tarekegn, A. N.; Giacobini, M.; and Michalak, K. 2021. A review of methods for imbalanced multi-label classifcation.Pattern Recognition, 118: 107965.

Trivedi, S. K.; Dey, S.; Kumar, A.; and Panda, T. K. 2017.Handbook of research on advanced data mining techniques and applications for business intelligence. IGI Global.

Wang, Q.; Shen, B.; Wang, S.; Li, L.; and Si, L. 2014. Binary codes embedding for fast image tagging with incomplete la bels. In ECCV, 425‚Äì439.

Wang, S.; Minku, L. L.; and Yao, X. 2014. Resampling based ensemble methods for online class imbalance learn ing. IEEE Transactions on Knowledge and Data Engineer ing, 27(5): 1356‚Äì1368.

Wei, Q.; Feng, L.; Sun, H.; Wang, R.; Guo, C.; and Yin,Y. 2023. Fine-grained classifcation with noisy labels. In CVPR, 11651‚Äì11660.

Wei, T.; Shi, J.-X.; Tu, W.-W.; and Li, Y.-F. 2021.Ro bust long-tailed learning under label noise. arXiv preprint arXiv:2108.11569.

Whang, S. E.; Roh, Y.; Song, H.; and Lee, J.-G. 2021.Data Collection and Quality Challenges in Deep Learn ing: A Data-Centric AI Perspective.arXiv preprint arXiv:2112.06409.

Wu, T.; Huang, Q.; Liu, Z.; Wang, Y.; and Lin, D. 2020.Distribution-balanced loss for multi-label classifcation in long-tailed datasets. In ECCV, 162‚Äì178.

Xia, X.; Liu, T.; Han, B.; Gong, M.; Yu, J.; Niu, G.; and Sugiyama, M. 2022. Sample selection with uncertainty of losses for learning with noisy labels. In ICLR.

Yuan, J.; Zhang, Y.; Shi, Z.; Geng, X.; Fan, J.; and Rui, Y.2023. Balanced masking strategy for multi-label image clas sifcation. Neurocomputing, 522: 64‚Äì72.

Zhang, H.; Cisse, M.; Dauphin, Y. N.; and Lopez-Paz, D.2018. Mixup: Beyond empirical risk minimization. In ICLR.Zhang, M.; Hu, L.; Shi, C.; and Wang, X. 2020. Adversarial label-fipping attack and defense for graph neural networks.In ICDM, 791‚Äì800.

Zhang, S.; Li, Z.; Yan, S.; He, X.; and Sun, J. 2021. Distri bution alignment: A unifed framework for long-tail visual recognition. In CVPR, 2361‚Äì2370.

Zhao, W.; and Gomes, C. 2021. Evaluating multi-label clas sifers with noisy labels. arXiv preprint arXiv:2102.08427.

# A. Pseudocode

The overall procedure of BalanceMix is described in Algo rithm 1, which is simple and self-explanatory. During the warm-up phase, it updates the model with a standard ap proach using the BCE loss on the minority-augmented mini batch. After the warm-up phase, fne-grained label-wise management is performed before generating the minority augmented mini-batch; in detail, all labels are processed and categorized into clean, re-labeled, and ambiguous ones.Next, the two mini-batches are mixed by Eq. (5) with the refned labels. Then, the model is updated by the proposed loss function in Eq. (10).

Algorithm 1: BalanceMix

INPUwTa: rm $\tilde {\mathcal {D}}$ :: nwoaisrym d-uapta ,e bp:o bcahtsc,h $Œ±$ si:z em, iexpuopc hc:o etrfaficniienngt ,e pœµo: crhes labeling threshold

OUTPUT: $Œò_{t}:$  DNN parameters

1: Œò $\leftarrow$ Initialize DNN parameters;

2: for $i=1$  to epoch do

3: $\text {for}j=1$  to $\vert \tilde {\mathcal {D}}\vert /b\mathbf {do}$ 

4: /* Sampling from two samplers $*/$ 

5: Draw a mini-batch $B_{R}$ by the random sampler;

6: Draw a mini-batch $B_{M}$  by the minority sampler;

7: if $i\leq$ warm then

8: $/*$  Update with given labels $*/$ 

9: Generate a mini-batch $B_{mix}$ by Eq. (5);

10: Update the model by Eq. (1);

11: else

12: $/*$ Update with label management $*/$ 

13: Perform the label-wise management;

14: Generate a mini-batch $B_{\text {mix}}$  by Eq. (5);

15: Update the model by Eq. (10);

16: /* Update the minority sampler and GMMs */

17: Update the sampling probability by Eq. (4);

18: Fitting the GMMs to the loss of entire data;

19: return Œò

# B. Analysis of Minority Sampling

We analyze the correlation between average precision and prediction confdence in the presence of noisy labels. Fig ure 3 was obtained without label noise. Figure 5 is obtained with label noise. The Perason correlation coeffcient is still very high, though the absolute values of the confdence and precision are decreased owing to label noise. The coeffcient was calculated between ten class groups.

In addition, we show how the sampling probability changes with our confdence-based minority oversampling method in Figure 6. Minority instances are initially oversam pled with a high probability, but the degree of oversampling gradually decreases as the imbalance problem gets resolved.

# C. Imbalance in Benchmark Datasets

We investigate the imbalance of positive labels across classes in three benchmark datasets, Pascal-VOC3, MS-

3http://host.robots.ox.ac.uk/pascal/VOC/

<!-- e 1 d i f cne0.75Pceoaerfsfoicnie cnotr =re l0a.t9io9n3 n o C 0.5 .  d e 0.25 0 PrTen Class Groups  (Sorted by # Positive Labels) -->
![](https://web-api.textin.com/ocr_image/external/8d2af390025a7c8f.jpg)

<!-- n 100 io s i 75 ec r P 50 g  v 25 0 ATen Class Groups  (Sorted by # Positive Labels) -->
![](https://web-api.textin.com/ocr_image/external/dadc83a6326d41d4.jpg)

Figure 5: Prediction confdence (left) and average precision (right) in COCO with mislabeling of $40\%$  at the $40\%$  of training epochs.

<!-- 3.8E-05Rand. Sampler i l tyMinor. Sampler (Max) i abMinor. Sampler (Min) b 2.5E-05 o r P   g in l 1.3E-05 p m a S 0.0E+00 11020304050 Epochs -->
![](https://web-api.textin.com/ocr_image/external/360b512e0678991c.jpg)

Figure 6: Sampling probability over the training period.

$\mathrm {COCO}^{4}$ , and DeepFashion5. We use a fne-grained subset of DeepFashion with 16,000 training and 4,000 validation in stances as well as multi-labels of 26 attribute classes, which are provided by the authors. Fig. 7 shows the distribution of the numbers of positive labels across classes, where the dashed lines split the classes into many-shot $[10000,\infty )$ ,medium-shot [1000, 10000), and few-shot $[0,1000)$  classes;Pascal-VOC does not have the many-shot classes.

A few majority classes occupy most of the positive labels in the data. Hence, we defne the class imbalance ratio fol lowing the literature (Zhang et al. 2021; Park et al. 2022),

$$\text {CLS_{Imb}.}=\max _{1\leq i\leq k}N_{i}/\min _{1\leq i\leq k}N_{i}\tag{12}$$

which is the maximum ratio of the number of positive labels in the majority class to that in the minority class. In addition,an image contains few positive labels but many negative la bels. Hence, we defne the positive-negative ratio by

$$\text {PN_{Imb}.}=\sum _{1\leq i\leq k}N_{i}^{\prime }/\sum _{1\leq i\leq k}N_{i}\tag{13}$$

where $N_{i}^{\prime }$ is the number of negative labels for the $i$ -th class.As for these two imbalance ratios, Pascal-VOC, MS-COCO,and DeepFashion have class imbalance ratios of 14, 339, and 239, and positive-negative imbalance ratios of 13, 27, and 3,respectively.

# D. Detailed Experiment Confguration

All the algorithms are implemented using Pytorch 21.11 and run using two NVIDIA V100 GPUs utilizing distributed data parallelism. We fne-tune ResNet-50 pre-trained on ImageNet-1K for 20, 50, and 40 epochs for Pascal-VOC (a batch size of 32), MS-COCO (a batch size of 64), and Deep Fashion (a batch size of 64) using an SGD optimizer with a momentum of 0.9 and a weight decay of $10^{-4}$ . All the

4https://cocodataset.org/

5https://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html

<!-- Pascal-VOC 15101520 Classes (sorted) -->
![](https://web-api.textin.com/ocr_image/external/74384e24a434e171.jpg)

Figure 7: Imbalanced labels of the three benchmark datasets.

<!-- MS-COCO 120406080 Classes (sorted) -->
![](https://web-api.textin.com/ocr_image/external/a2b93a5a3bb7c600.jpg)

<!-- DeepFashion 16111626 21 Classes (sorted) -->
![](https://web-api.textin.com/ocr_image/external/1e58f5982a855856.jpg)


| œµ | Mis. 20% | Mis. 40% | œµ | Missing Label  |
| --- | --- | --- | --- | --- |
| 1.000  | 82.5  | 77.8  | 0.550  | 77.4  |
| 0.975  | 84.3  | 81.4  | 0.600  | 77.3  |
| 0.950  | 84.0  | 81.5  | 0.700  | 76.8  |
| 0.900  | 83.7  | 81.3  | 0.900  | 76.3  |


Table 7: Parameter search for $E$  when fxing $Œ±=4.0.$ 


| Œ± | All  | Many  | Medium  | Few  |
| --- | --- | --- | --- | --- |
| 1.0  | 80.3  | 84.8  | 81.2  | 63.2  |
| 2.0  | 81.1  | 85.6  | 82.3  | 60.3  |
| 4.0  | 81.6  | 85.5  | 82.6  | 63.1  |
| 8.0  | 81.3  | 85.1  | 82.5  | 60.1  |


Table 8: Parameter search for $Œ±$  when fxing $Œµ=0.975.$ 


| Class Group  | Class Group  | MS-COCO  | MS-COCO  | MS-COCO  | MS-COCO  | MS-COCO  | Pascal-VOC  | Pascal-VOC  | Pascal-VOC  | Pascal-VOC  | Pascal-VOC  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Category  | Method  | Mis. 20% | Mis. 40% | Rand. 20% | Rand. 40% | Single  | Mis. 20% | Mis. 40% | Rand. 20% | Rand. 40% | Single  |
| Default  | BCE Loss  | 73.1¬±0.4 | 63.8¬±0.8 | $59.8\pm 0.5$ | 43.5¬±0.8 | $69.7\pm 1.8$ | $82.9\pm 0.1$ | 75.4¬±0.3 | 76.3¬±0.5 | 72.0¬±5.5 | 85.7¬±0.1 |
| Noisy Labels  | Co-teaching  | 82.5¬±0.1 | 78.6¬±0.4 | $65.5\pm 0.0$ | $43.6\pm 0.1$ | $68.1\pm 1.4$ | $92.5\pm 0.3$ | $90.9\pm 0.1$ | $82.6\pm 0.4$ | $70.0\pm 0.4$ | 81.9¬±1.6 |
| Noisy Labels  | ASL  | 82.8¬±0.1 | 80.3¬±0.2 | $75.0\pm 0.1$ | $66.2\pm 0.1$ | $73.3\pm 0.2$ | $91.2\pm 0.0$ | $86.4\pm 0.1$ | $90.1\pm 0.1$ | $74.8\pm 0.3$ | 86.8¬±0.1 |
| Missing Labels  | LL-R  | 80.7¬±0.1 | 75.3¬±0.2 | $74.0\pm 0.2$ | $69.3\pm 0.2$ | $74.2\pm 0.2$ | $87.5\pm 0.5$ | 83.1¬±1.2 | $85.5\pm 0.3$ | $78.6\pm 2.2$ | 89.1¬±0.4 |
| Missing Labels  | LL-Ct  | 81.3¬±0.0 | 77.4¬±0.1 | $73.2\pm 0.3$ | $70.1\pm 0.1$ | $76.9\pm 0.1$ | $88.8\pm 0.5$ | $84.8\pm 1.4$ | $87.1\pm 0.2$ | 78.8¬±0.3 | 89.3¬±0.1 |
| Proposed  | BalanceMix  | 84.3¬±0.1 | 81 $.6\pm 0.3$ | $76.5\pm 0.1$ | $74.5\pm 0.1$ | $77.4\pm 0.1$ | $92.9\pm 0.1$ | $92.0\pm 0.0$ | $91.2\pm 0.1$ | $84.4\pm 0.1$ | 92.6¬±0.1 |


Table 9: Last mAPs on MS-COCO and Pascal-VOC with standard errors.

images are resized with $448x448$ resolution. The initial learning rate is set to be 0.01 and decayed with a cosine annealing without restart. The number of warm-up epochs is set to be 5, 10, and 5 for the three datasets, respec tively. We adopt a state-of-the-art Transformer-based de coder (Lanchantin et al. 2021; Liu et al. 2021; Ridnik et al.2023) for the classifcation head. These experiment setups are exactly the same for all compared methods.

The hyperparameters for the compared methods are con fgured favorably, as suggested in the original papers.

‚Ä¢ Co-teaching (Han et al. 2018): We extend the vanilla ver sion to support multi-label classifcation. Two models are maintained for co-training. Instead of using the known noise ratio, we ft a bi-modal univariate GMM to the losses of all instances, i.e., instance-level modeling. Then,the instances whose probability of being clean is greater than 0.5 are selected as clean instances.

‚Ä¢ ASL (Ben-Baruch et al. 2021): Three hyperparameters ‚Äì $Œ≥^{+}$ which is a down-weighting coeffcient for positive la bels, $Œ≥^{-}$ which is a down-weighting coeffcient for nega $m$ tive labels, and m which is a probability margin ‚Äì are set to be 0.0, 4.0, and 0.05, respectively.

‚Ä¢ LL-R & LL-Ct (Kim et al. 2022): The only hyperparame ter is $\Delta _{\text {rel}},$  which determines the speed of increasing the rejection (or correction) rate. The default value used in the original paper was 0.2 for 10 epochs. Hence, we mod ify the value according to our training epochs, such that the rejection (or correction) ratios at the fnal epoch are the same. Specifcally, it is set to be 0.1 for 20 epochs (Pascal-VOC), 0.04 for 50 epochs (MS-COCO), and 0.05for 40 epochs (DeepFashion), respectively.

Regarding the state-of-the-art comparison with ResNet 101 and TResNet-L, we follow exactly the same settings in the backbone, image resolution, and data augmentation (Ridnik et al. 2023). See Table 5 for details.

# E. Hyperparameters

BalanceMix introduces two hyperparameters: œµ, a conf dence threshold for re-labeling and $Œ±$ , the parameter of the beta distribution for Mixup. We search for a suitable pair of these two hyperparameters based on MS-COCO.

First, we fx $Œ±=4.0$  and conduct a grid search to fnd the best œµ, as summarized in Table 7. Intuitively, a high thresh old value achieves high precision in re-labeling, while a low threshold value achieves high recall. For mislabeling, high precision is more benefcial than high recall; thus, the in terval of 0.950‚Äì0.975 exhibits the best mAP. However, in the missing (single positive) label setup, high recall precedes high precision because increasing the amount of positive la bels is more benefcial; thus, the interval of 0.550‚Äì0.600 ex hibits the best mAP. Overall, we use $Œµ=0$ .550 for the miss ing label setup, while $Œµ=0$ .975 for other setups.

Second, we fx $Œµ=0.975$ and repeat a grid search for the best $Œ±$ . Table 8 summarizes the mAPs on MS-COCO


| Class Group  | Class Group  | All  | All  | All  | Medium-shot  | Medium-shot  | Medium-shot  | Few-shot  | Few-shot  | Few-shot  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Category  | Method  | 0% | 20% | 40% | 0% | 20% | 40% | 0% | 20% | 40% |
| Default  | BCE Loss  | 87.7  | 82.9  | 75.4  | 94.1  | 85.3  | 77.1  | 84.9  | 81.8  | 74.8  |
| Noisy Labels  | Co-teaching  | 90.8  | 92.5  | 90.9  | 93.9  | 94.0  | 92.8  | 89.4  | 91.8  | 90.0  |
| Noisy Labels  | ASL  | 91.4  | 91.2  | 86.4  | 92.9  | 92.4  | 80.5  | 90.8  | 90.7  | 88.9  |
| Noisy Labels  | T-estimator  | 91.0  | 89.5  | 89.0  | 92.4  | 91.9  | 91.6  | 90.2  | 88.5  | 87.9  |
| Missing Labels  | LL-R  | 81.8  | 87.5  | 83.1  | 92.5  | 89.6  | 85.7  | 77.2  | 86.6  | 81.9  |
| Missing Labels  | LL-Ct  | 84.0  | 88.8  | 84.8  | 90.3  | 90.7  | 87.9  | 81.3  | 87.9  | 83.5  |
| Proposed  | BalanceMix  | 93.3  | 92.9  | 92.0  | 95.1  | 94.4  | 93.6  | 92.5  | 92.2  | 91.3  |


Table 10: Last mAPs on Pascal-VOC with mislabeling of $0-40\%$ . The 1st and 2nd best values are in bold and underlined.


| Class Group  | Class Group  | All  | All  | All  | Medium-shot  | Medium-shot  | Medium-shot  | Few-shot  | Few-shot  | Few-shot  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Category  | Method  | 0% | 20% | 40% | 0% | 20% | 40% | 0% | 20% | 40% |
| Default  | BCE Loss  | 87.7  | 76.3  | 72.0  | 94.1  | 80.0  | 74.4  | 84.9  | 74.8  | 71.0  |
| Noisy Labels  | Co-teaching  | 90.8  | 82.6  | 70.3  | 93.9  | 87.1  | 82.8  | 89.4  | 80.6  | 64.9  |
| Noisy Labels  | ASL  | 91.4  | 90.1  | 74.8  | 92.9  | 92.3  | 87.6  | 90.8  | 89.2  | 69.3  |
| Noisy Labels  | T-estimator  | 91.0  | 85.9  | 70.1  | 92.4  | 89.3  | 80.3  | 90.2  | 84.4  | 65.6  |
| Missing Labels  | LL-R  | 81.8  | 85.5  | 78.6  | 92.5  | 88.8  | 83.0  | 77.2  | 84.0  | 76.8  |
| Missing Labels  | LL-Ct  | 84.0  | 87.1  | 78.8  | 90.3  | 89.3  | 82.9  | 81.3  | 86.1  | 77.1  |
| Proposed  | BalanceMix  | 93.3  | 91.2  | 84.4  | 95.1  | 93.8  | 91.7  | 92.5  | 90.0  | 81.3  |


Table 11: Last mAPs on Pascal-VOC with random fipping of $0-40\%$ . The 1st and 2nd best values are in bold and underlined.


| Mixing<br>coef. Œ± | 0.0  | 1.0  | 2.0  | 4.0  | 8.0  |
| --- | --- | --- | --- | --- | --- |
| Many-shot  | 85.4  | 85.6  | 85.1  | 85.5  | 84.8  |
| Few-shot  | 57.4  | 60.3  | 62.4  | 63.1  | 63.2  |


Table 12: Varying $Œ±$  on COCO with mislabeling of $40\%$ .

with a mislabeling ratio of $40\%$ . The best mAP for many shot classes is observed when $Œ±=2.0.$  However, the overall mAP of BalanceMix is the best when $Œ±=4.0$  owing to the highest mAP on medium-shot and few-shot classes. There fore, we use $Œ±=4.$ $.0$  in general.

These hyperparameter values found may not be optimal as we validate them only in a few experiment settings, but BalanceMix shows satisfactory performance with them in all the experiments presented in the paper. We believe that the performance of BalanceMix could be further improved via a more sophisticated parameter search.

# F. Additional Main Results

# Results with Standard Errors

Table 9 summarizes the last mAPs on MS-COCO and Pascal-VOC. We repeat the experiments thrice and report the averaged mAPs as well as their standard errors. These standard errors are, in general, very small.

# Results on Pascal-VOC

Tables 10 and 11 summarize the mAPs on Pascal-VOC with mislabeing and random fipping. The performance trends are similar to those on MS-COCO except that Co-teaching exhibits higher mAPs than ASL in the mislabeling noise.In Pascal-VOC unlike MS-COCO, the number of positive labels per instance is only two on average. Therefore, the


| Method  | Clean  | Mis. 40% | Rand. 40% | Missing  |
| --- | --- | --- | --- | --- |
| Co-teaching  | 82.8  | 78.6  | 43.6  | 68.1  |
| T-estimator  | 84.3  | 80.5  | 69.9  | 16.8  |
| LL-R  | 82.5  | 75.3  | 69.3  | 74.2  |
| LL-Ct  | 79.4  | 77.4  | 70.1  | 76.9  |
| BalanceMix (wo Min.)  | 85.0  | 80.9  | 73.0  | 77.0  |


Table 13: Analysis of BalanceMix w.o using the minority sampler on MS-COCO.

instance-level selection of Co-teaching can perform better than ASL. However, in the random fipping noise where even negative labels are fipped by a given noise ratio, Co teaching is much worse than ASL. BalanceMix consistently exhibits the best mAPs for all class categories. Regarding T-estimator, it performs much better than BCE Loss and exhibits comparable performance to Co-teaching and ASL,even if $10\%$  of training data is not used for training since it is required for the noisy validation set.

## G. Analysis of Label-wise Management

### G.1. Mixing with Different Diversity

The diversity is added by mixing the instances from the ran dom sampler with the instances from the minority sampler via Mixup. Thus, when the Mixup coeffcient Œ± is $Œ±$  $0$ , mixing is not performed at all, and the diversity is the lowest. On the other hand, as $Œ±$  becomes larger, minority samples are more strongly mixed with random samples, and the diversity gets higher. As shown in Table 12, increasing the value of Œ± $Œ±$ enhances few-shot class performance, but excessive adjust ments degrade many-shot class performance; when $Œ±=0,$ a low performance of few-shot classes is attributed to the overftting caused by limited diversity.


|  | Clean Label Selection (C by Eq. (8))  | Clean Label Selection (C by Eq. (8))  | Clean Label Selection (C by Eq. (8))  | Clean Label Selection (C by Eq. (8))  | Re-labeling (R by Eq. (9))  | Re-labeling (R by Eq. (9))  | Re-labeling (R by Eq. (9))  | Re-labeling (R by Eq. (9))  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Noise Type  | Mislabel 20% | Mislabel 20% | Mislabel 40% | Mislabel 40% | Mislabel 20% | Mislabel 20% | Mislabel 40% | Mislabel 40% |
| Training Progress  | Precision  | Recall  | Precision  | Recall  | Proportion  | Accuracy  | Proportion  | Accuracy  |
| 25% Epochs  | 99.2% | 85.3% | 96.1% | 90.5% | 10.1% | 98.6% | 12.0% | 98.9% |
| 50% Epochs  | 99.0% | 88.9% | 95.5% | 92.7% | 9.1% | 98.6% | 11.2% | 98.8% |
| 100% Epochs  | 98.6% | 91.5% | 94.5% | 94.3% | 8.3% | 98.5% | 9.1% | 98.5% |


Table 14: Clean label selection and re-labeling performance of BalanceMix on MS-COCO: 2nd-5th columns summarize the label precision and label recall of selecting clean labels, and 6th-9th columns summarize the proportion of re-labeled labels and their re-labeling accuracy.


|  | Clean Label Selection (C by Eq. (8))  | Clean Label Selection (C by Eq. (8))  | Clean Label Selection (C by Eq. (8))  | Clean Label Selection (C by Eq. (8))  | Re-labeling (R by Eq. (9))  | Re-labeling (R by Eq. (9))  | Re-labeling (R by Eq. (9))  | Re-labeling (R by Eq. (9))  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Noise Type  | Mislabel 20% | Mislabel 20% | Mislabel 40% | Mislabel 40% | Mislabel 20% | Mislabel 20% | Mislabel 40% | Mislabel 40% |
| Training Progress  | Precision  | Recall  | Precision  | Recall  | Proportion  | Accuracy  | Proportion  | Accuracy  |
| 25% Epochs  | 99.6% | 88.0% | 98.2% | 91.5% | 2.9% | 97.4% | 2.0% | 97.4% |
| 50% Epochs  | 99.3% | 93.6% | 97.2% | 94.8% | 6.9% | 98.8% | 5.9% | 98.8% |
| 75% Epochs  | 99.2% | 94.4% | 97.0% | 95.5% | 8.6% | 99.0% | 7.0% | 99.0% |
| 100% Epochs  | 99.2% | 95.0% | 96.7% | 95.9% | 8.6% | 99.1% | 6.8% | 99.1% |


Table 15: Clean label selection and re-labeling performance of BalanceMix on Pascal-VOC: 2nd-5th columns summarize the label precision and label recall of selecting clean labels, and 6th-9th columns summarize the proportion of re-labeled labels and their re-labeling accuracy.

### G.2. Pure Effect of Label-wise Management

We compare solely the label-wise management with the refnement-based methods (Co-teaching, T-estimator, LL R, and LL-Ct) by excluding the additional gains from the minority sampler. Thus, we replace the minority sam pler of BalanceMix with the random sampler because the refnement-based methods use the random Mixup. Then,the remaining differences of BalanceMix from others are (1) the defnition of ambiguous labels and (2) the diminu tion of their loss based on inferred clean probabilities. Ta ble 13 shows the result of such comparison, clearly showing the pure superiority of our label-wise refnement over other counterparts.

### G.3. Label Precision and Label Recall

The label-wise management of BalanceMix involves select ing clean labels and re-labeling incorrect labels. There are four metrics to evaluate clean label selection and re-labeling performance. Regarding label selection, there are two indi cators, label precision and recall, of evaluating how accurate and how many clean labels are chosen from noisy labels,respectively (Han et al. 2018; Song et al. 2022). For conve nience, let C be the set of all selected labels from all noisy labels, and L be the set of all clean labels. Then, the label precision and recall are formulated as:

Label Precisio $\mathrm {n}=\vert \{\tilde {y}\in \mathrm {C}:$ $\tilde {y}=y\}\vert /\vert \mathrm {C}\vert$ 

(14)

Label R $\text {ecall}=\vert \{\tilde {y}\in \mathrm {C}:$ $\tilde {y}=y\}\vert /\vert \mathrm {L}\vert .$ 

Regarding re-labeling, we evaluate its performance based on the proportion of re-labeled labels and their re-labeling ac curacy. Let R be the re-labeled labels among all noisy labels,and D be the entire label in data. Then, the proportion and accuracy are formulated as:

Relabel Proporti $\mathrm {on}=\vert \mathrm {R}\vert /\vert \mathrm {D}\vert ,$ 

(15)

$$\text {RelabelAccuracy}=\vert \{\tilde {y}\in \mathrm {R}:\quad \tilde {y}=y\}\vert /\vert \mathrm {R}\vert .$$Table 14 summarizes their performance on MS-COCO at three different learning progress. For label selection, we evaluate label precision and recall (Han et al. 2018; Song et al. 2022) of the selected clean labels, where they are in dicators of how accurate and how many clean labels are chosen, respectively. BalanceMix exhibits very high preci sion and recall, and the recall increases greatly as train ing progresses without compromising the precision. For re labeling, we evaluate the percentage of re-labeled labels and their accuracy. BalanceMix keeps very high re-labeling ac curacy in all training phases. Thus, as the model continues to evolve, more clean labels are selected with high precision,and incorrect labels are re-labeled with high accuracy.

Table 15 summarizes their performance on Pascal-VOC at three different learning progress. In Pascal-VOC, Bal anceMix exhibits similar trends of label selection, compared when using MS-COCO. However, we observe that the num ber of re-labeled labels shows a different trend in MS-COCO and Pascal-VOC. The number increases over training epochs in Pascal-VOC, but an opposite trend is observed in MS COCO. We expect that the re-labeling performance may be associated with the learning diffculty of training data and the number of classes in training data. We will leave further analysis of re-labeling as future work.

#### H. Noisy Labels in MS-COCO

It is of interest to see a signifcant improvement of Bal anceMix on MS-COCO in our state-of-the-art comparison (see Table 5). It turns out that MS-COCO originally has in correct and missing labels. Fig. 8 shows a few successfully re-labeled examples from MS-COCO by BalanceMix. The frst row shows four examples with incorrect labels, and the second row shows four examples with missing labels. As an example with the frst image, an oven is mislabeled as a positive label, but it is re-labeled as a negative one by


![](https://web-api.textin.com/ocr_image/external/2da4a98c53da7cd1.jpg)

Given: 


![](https://web-api.textin.com/ocr_image/external/5101fef44ba32ef4.jpg)


![](https://web-api.textin.com/ocr_image/external/036b6f89a9a9f904.jpg)

[cake, chair, cup, dining table, person, oven]

Given: 

Given: 

Corrected: 

[cake, chair, cup, dining table, person]


![](https://web-api.textin.com/ocr_image/external/f1666112fa2730f1.jpg)

[bus, person, tie]

[car, motorcycle, person, traffic light]

Corrected: 

Corrected: 

Given: 

[chair, wine glass]

[person, tie]

[car, motorcycle, person]

Corrected: 

[cat, chair, wine glass]


![](https://web-api.textin.com/ocr_image/external/78f6b46c93aca926.jpg)


![](https://web-api.textin.com/ocr_image/external/ed221f35735297e7.jpg)

Given: 

Given: 

[dining table, orange]

[backpack, handbag, suitcase]

Corrected: 

Corrected: 

[bowl, dining table, orange]

[backpack, handbag, suitcase, person]


![](https://web-api.textin.com/ocr_image/external/85444e6dc44bc89f.jpg)

Given: 

[bench, cat, fire hydrant]

Corrected: 

[bench, cat]


![](https://web-api.textin.com/ocr_image/external/e526e9f4f76d0ade.jpg)

Given: 

[Chair, couch, bed]

Corrected:

[Chair, couch, bed, teddy bear]

Figure 8: Examples of incorrect and missing labels originally contained in MS-COCO. The red labels (incorrect labels) and green labels (missing labels) are detected and corrected by BalanceMix during training.

BalanceMix. As an example with the ffth image, a cat is omitted in labeling, but it is re-labeled as a positive one by BalanceMix. Therefore, the state-of-the-art performance of BalanceMix in MS-COCO is attributed to its versatility for real noisy and imbalanced labels.

